{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Employee Attrition Prediction using IBM HR Analytics Dataset\nThis notebook walks through the full pipeline to build a predictive model for employee attrition and derive actionable HR insights using EDA, machine learning, and SHAP explainability."}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 1: Load and Preprocess Data\nWe start by importing the dataset and applying basic preprocessing steps including dropping constant/irrelevant columns, binary encoding, and one-hot encoding."}, {"cell_type": "code", "metadata": {}, "source": "import pandas as pd\ndf = pd.read_csv(\"/content/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n# Drop irrelevant columns\ndf.drop(columns=[\"EmployeeNumber\", \"EmployeeCount\", \"Over18\", \"StandardHours\"], inplace=True)\n\n# Binary encoding\ndf[\"Attrition\"] = df[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\ndf[\"Gender\"] = df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\ndf[\"OverTime\"] = df[\"OverTime\"].map({\"Yes\": 1, \"No\": 0})\n\n# One-hot encoding for categorical variables\ncategorical_cols = [\"BusinessTravel\", \"Department\", \"EducationField\", \"JobRole\", \"MaritalStatus\"]\ndf = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 2: Exploratory Data Analysis (EDA)\nWe analyze class distribution and correlations to understand key drivers of attrition."}, {"cell_type": "code", "metadata": {}, "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Attrition class distribution\nsns.countplot(x=\"Attrition\", data=df)\nplt.title(\"Attrition Distribution\")\nplt.show()\n\n# Correlation with target\ncorr = df.corr()[\"Attrition\"].sort_values(ascending=False)\nprint(\"Top correlated features with Attrition:\\n\", corr.head(10))"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 3: Train-Test Split and Modeling\nWe train Random Forest and Logistic Regression models after stratified train-test splitting."}, {"cell_type": "code", "metadata": {}, "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nX = df.drop(\"Attrition\", axis=1)\ny = df[\"Attrition\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Random Forest\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\nprint(\"Random Forest Classification Report:\")\nprint(classification_report(y_test, rf_model.predict(X_test)))\n\n# Logistic Regression\nlr_model = LogisticRegression(max_iter=1000)\nlr_model.fit(X_train, y_train)\nprint(\"Logistic Regression Classification Report:\")\nprint(classification_report(y_test, lr_model.predict(X_test)))"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 4: Model Explainability with SHAP\nWe use SHAP to understand which features contribute most to predictions."}, {"cell_type": "code", "metadata": {}, "source": "import shap\nexplainer = shap.Explainer(rf_model, X_test)\nshap_values = explainer(X_test)\nshap.summary_plot(shap_values, X_test)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 5: Actionable Insights\nBased on feature importance, here are actionable insights:\n- High overtime increases attrition risk \u2192 reduce workload or offer flexible shifts.\n- Low income correlates with attrition \u2192 consider salary adjustment.\n- Long commutes may lead to resignations \u2192 offer hybrid/remote options.\n- Young employees with low experience may leave \u2192 improve onboarding and career paths."}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}